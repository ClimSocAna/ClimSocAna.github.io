<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paper-Conference | Climate and Societal Analytics</title>
    <link>http://localhost:1313/publication-type/paper-conference/</link>
      <atom:link href="http://localhost:1313/publication-type/paper-conference/index.xml" rel="self" type="application/rss+xml" />
    <description>Paper-Conference</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Thu, 01 Aug 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>Paper-Conference</title>
      <link>http://localhost:1313/publication-type/paper-conference/</link>
    </image>
    
    <item>
      <title>Guiding Sentiment Analysis with Hierarchical Text Clustering: Analyzing the German X/Twitter Discourse on Face Masks in the 2020 COVID-19 Pandemic</title>
      <link>http://localhost:1313/publications/conference-paper/wehrli-etal-2024-guiding/</link>
      <pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publications/conference-paper/wehrli-etal-2024-guiding/</guid>
      <description>&lt;p&gt;Social media are a critical component of the information ecosystem during
public health crises. Understanding the public discourse is essential for effective
communication and misinformation mitigation. Computational methods can aid these
efforts through online social listening. We combined hierarchical text clustering
and sentiment analysis to examine the face mask-wearing discourse in Germany during
the COVID-19 pandemic using a dataset of 353,420 German X (formerly Twitter) posts
from 2020. For sentiment analysis, we annotated a subsample of the data to train
a neural network for classifying the sentiments of posts (neutral, negative, or
positive). In combination with clustering, this approach uncovered sentiment patterns
of different topics and their subtopics, reflecting the online public response to
mask mandates in Germany. We show that our approach can be used to examine long-term
narratives and sentiment dynamics and to identify specific topics that explain peaks
of interest in the social media discourse.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linguistic markers of schizophrenia: a case study of Robert Walser</title>
      <link>http://localhost:1313/publications/conference-paper/nenchev-etal-2024-linguistic/</link>
      <pubDate>Fri, 01 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publications/conference-paper/nenchev-etal-2024-linguistic/</guid>
      <description>&lt;p&gt;Add the &lt;strong&gt;full text&lt;/strong&gt; or &lt;strong&gt;supplementary notes&lt;/strong&gt; for the publication here using Markdown formatting.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>German Text Embedding Clustering Benchmark</title>
      <link>http://localhost:1313/publications/conference-paper/wehrli-etal-2023-german/</link>
      <pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publications/conference-paper/wehrli-etal-2023-german/</guid>
      <description>&lt;p&gt;This work introduces a benchmark assessing the performance of clustering German text embeddings in different domains. This benchmark is driven by the increasing use of clustering neural text embeddings in tasks that require the grouping of texts (such as topic modeling) and the need for German resources in existing benchmarks. We provide an initial analysis for a range of pre-trained mono- and multilingual models evaluated on the outcome of different clustering algorithms. Results include strong performing mono- and multilingual models. Reducing the dimensions of embeddings can further improve clustering. Additionally, we conduct experiments with continued pre-training for German BERT models to estimate the benefits of this additional training. Our experiments suggest that significant performance improvements are possible for short text. All code and datasets are publicly available.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
